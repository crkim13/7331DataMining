{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanded - Predicting the Four and Five Year Graduation Rates for Public High Schools\n",
    "**This notebook explores predicting the 4 and 5 year graduation rates for public high schools in North Carolina.** \n",
    "* Public school racial compositions are also considered when making predictions in this notebook.\n",
    "* The North Carolina Educational Attainment Data Repository for Machine Learning is located on Github at: https://github.com/jakemdrew/EducationDataNC \n",
    "* The dataset used in this notebook is created prepared for machine learning in the notebook: \n",
    "  NC EA Public High Schools Dataset Expaneded Feb 2018\n",
    "* The dataset name used in this notbook is: \n",
    "  HighSchoolsML_02_2018_Expanded.csv\n",
    "\n",
    "**For documentation on various Generalized Linear Models in Sklearn see:**\n",
    "* http://scikit-learn.org/stable/modules/linear_model.html\n",
    "* https://stackoverflow.com/questions/33845539/modelling-probabilities-in-a-regularized-logistic-regression-model-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 440 entries, 0 to 439\n",
      "Columns: 140 entries, title1_type_flg to 1_to_1_access_Yes\n",
      "dtypes: bool(6), float64(114), int64(20)\n",
      "memory usage: 463.3 KB\n"
     ]
    }
   ],
   "source": [
    "#import required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Read in the high schools dataset - NC EA Public High Schools Dataset Feb 2018\n",
    "url=\"https://raw.githubusercontent.com/jakemdrew/EducationDataNC/master/Machine%20Learning%20Datasets/HighSchoolsML_02_2018_Expanded.csv\"\n",
    "schData=pd.read_csv(url, low_memory=False)\n",
    "\n",
    "#inspect data \n",
    "schData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 440 entries, 0 to 439\n",
      "Columns: 137 entries, title1_type_flg to 1_to_1_access_Yes\n",
      "dtypes: bool(6), float64(111), int64(20)\n",
      "memory usage: 453.0 KB\n"
     ]
    }
   ],
   "source": [
    "# create x explanatory and y response variables for regression\n",
    "Y_4yr_Gr = schData['Graduation_Rate4_Yr']\n",
    "Y_5yr_Gr = schData['Graduation_Rate_5_Yr']\n",
    "X_highSchools = schData.drop(['Graduation_Rate4_Yr', 'Graduation_Rate_5_Yr','Cohort Graduation Rate Standard Score'], axis=1)\n",
    "\n",
    "Y = Y_4yr_Gr\n",
    "\n",
    "#inspect data \n",
    "X_highSchools.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Scale dataset converting to standard normally distributed data \n",
    "# (e.g. Gaussian with 0 mean and unit variance).\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Fit to data for scaling\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(X_highSchools)\n",
    "\n",
    "#Transform training data to z-scores\n",
    "#This makes our model's coefficients take on the same scale for accurate feature importance analisys \n",
    "#X_highSchools = scaler.transform(X_highSchools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "**Cross validation is performed using repeated holdout using ShuffleSplit()**\n",
    "* Ten folds are used\n",
    "* The split is: 90% training data and 10% test data\n",
    "* A random seed is set so the same random test and training splits are used each time cross validation is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Divide data into test and training splits\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.10, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Scorers for Evaluating Regression Models \n",
    "\n",
    "**All regression models created in this notebook are validated using the following metrics:**\n",
    "* Mean Absolute Error (MAE)\n",
    "* Root Mean Squared Error (RMSE) - https://stackoverflow.com/questions/17197492/root-mean-square-error-in-python\n",
    "* Mean Absolute Percentage Error (MAPE) - https://stackoverflow.com/questions/42250958/how-to-optimize-mape-code-in-python\n",
    "\n",
    "**For details on making scorers to return multiple mean error scores see:**\n",
    "* http://scikit-learn.org/stable/auto_examples/model_selection/plot_multi_metric_evaluation.html\n",
    "* https://github.com/scikit-learn/scikit-learn/pull/7388\n",
    "* https://github.com/drorata/multiscorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Use mean absolute error (MAE) to score the regression models created \n",
    "#(the scale of MAE is identical to the response variable)\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error\n",
    "\n",
    "#Function for Root mean squared error\n",
    "#https://stackoverflow.com/questions/17197492/root-mean-square-error-in-python\n",
    "def rmse(y_actual, y_predicted):\n",
    "    return np.sqrt(mean_squared_error(y_actual, y_predicted))\n",
    "\n",
    "#Function for Mean Absolute Percentage Error (MAPE) - Untested\n",
    "#Adapted from - https://stackoverflow.com/questions/42250958/how-to-optimize-mape-code-in-python\n",
    "def mape(y_actual, y_predicted): \n",
    "    mask = y_actual <> 0\n",
    "    return (np.fabs(y_actual - y_predicted)/y_actual)[mask].mean() * 100\n",
    "\n",
    "#Create scorers for rmse and mape functions\n",
    "mae_scorer = make_scorer(score_func=mean_absolute_error, greater_is_better=False)\n",
    "rmse_scorer = make_scorer(score_func=rmse, greater_is_better=False)\n",
    "mape_scorer = make_scorer(score_func=mape, greater_is_better=False)\n",
    "\n",
    "#Make scorer array to pass into cross_validate() function for producing mutiple scores for each cv fold.\n",
    "errorScoring = {'MAE':  mae_scorer, \n",
    "                'RMSE': rmse_scorer,\n",
    "                'MAPE': mape_scorer\n",
    "               } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Evaluation\n",
    "** All regression models are evaluated using the regression model evaluation function below: ** \n",
    "* The following regression evaluation function uses the cross validation object and the custom scorers in the two cells above in combination with sklearn.model_selection's cross_validate function to perform cross validation for regression estimators.\n",
    "* The cross validation object above uses a random seed to ensure that all regression estimators are tested on the same randomly selected records for each cross validation fold.\n",
    "* Custom scorers are created using the three chosen mean error scores and passed into cross_validate(), so all three scores are calcualted using a single call to cross_validate().\n",
    "* All of this functionality is wrapped within the custom EvaluateRegressionEstimator() function below so multiple regression models may be tested using the same test / train cv data and evaluation scores producing a consistent output for each model without the need to re-write the same code over and over. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def EvaluateRegressionEstimator(regEstimator, X, y, cv):\n",
    "    \n",
    "    scores = cross_validate(regEstimator, X, y, scoring=errorScoring, cv=cv, return_train_score=True)\n",
    "\n",
    "    #cross val score sign-flips the outputs of MAE\n",
    "    # https://github.com/scikit-learn/scikit-learn/issues/2439\n",
    "    scores['test_MAE'] = scores['test_MAE'] * -1\n",
    "    scores['test_MAPE'] = scores['test_MAPE'] * -1\n",
    "    scores['test_RMSE'] = scores['test_RMSE'] * -1\n",
    "\n",
    "    #print mean MAE for all folds \n",
    "    maeAvg = scores['test_MAE'].mean()\n",
    "    print_str = \"The average MAE for all cv folds is: \\t\\t\\t {maeAvg:.5}\"\n",
    "    print(print_str.format(maeAvg=maeAvg))\n",
    "\n",
    "    #print mean test_MAPE for all folds\n",
    "    scores['test_MAPE'] = scores['test_MAPE']\n",
    "    mape_avg = scores['test_MAPE'].mean()\n",
    "    print_str = \"The average MAE percentage (MAPE) for all cv folds is: \\t {mape_avg:.5}\"\n",
    "    print(print_str.format(mape_avg=mape_avg))\n",
    "\n",
    "    #print mean MAE for all folds \n",
    "    RMSEavg = scores['test_RMSE'].mean()\n",
    "    print_str = \"The average RMSE for all cv folds is: \\t\\t\\t {RMSEavg:.5}\"\n",
    "    print(print_str.format(RMSEavg=RMSEavg))\n",
    "    print('*********************************************************')\n",
    "\n",
    "    print('Cross Validation Fold Mean Error Scores')\n",
    "    scoresResults = pd.DataFrame()\n",
    "    scoresResults['MAE'] = scores['test_MAE']\n",
    "    scoresResults['MAPE'] = scores['test_MAPE']\n",
    "    scoresResults['RMSE'] = scores['test_RMSE']\n",
    "    return scoresResults\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Four Year Graduation Rate - Baseline Regression Model\n",
    "\n",
    "**Linear Regression is used to create a baseline model.  Since linear regression may predict response variable values outside the range of the training data's response variable, we create a linear regression estimator with graduation rate predictions clipped 0% and 100%. For details see:**\n",
    "* http://scikit-learn.org/stable/developers/contributing.html#rolling-your-own-estimator \n",
    "* https://github.com/scikit-learn/scikit-learn/issues/6950\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "* https://github.com/scikit-learn-contrib/project-template/blob/master/skltemplate/template.py\n",
    "* https://stackoverflow.com/questions/44234682/how-to-use-sklearn-when-target-variable-is-a-proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make new estimator compatible for use with GridSearchCV() and cross_validate()\n",
    "# -  Cap predict function for LinearRegression between 0 and 100\n",
    "# -  See: Roll your own estimator links above for details. \n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "class CappedLinearRegression(LinearRegression):\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.clip(super(CappedLinearRegression, self).predict(X), 0, 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Grid Search\n",
    "** Here we perform a grid search testing 40 models to find the best parameters for our Linear Regression model based on Mean Absolute Error.  See more on parameter tuning with grid search here:**\n",
    "* http://scikit-learn.org/stable/modules/grid_search.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=0, test_size=0.1, train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=CappedLinearRegression(copy_X=True, fit_intercept=True, n_jobs=1,\n",
       "            normalize=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'normalize': (True, False), 'fit_intercept': (True, False)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a Linear Regression object and perform a grid search to find the best parameters\n",
    "linreg = CappedLinearRegression()\n",
    "parameters = {'normalize':(True,False), 'fit_intercept':(True,False)}\n",
    "\n",
    "#Create a grid search object using the  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=linreg\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv # KFolds = 10\n",
    "                   , scoring=mae_scorer)\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "regGridSearch.fit(X_highSchools, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CappedLinearRegression(copy_X=True, fit_intercept=False, n_jobs=1,\n",
       "            normalize=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the parameterization of the best estimator\n",
    "regGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Four Year Graduation Rate - Baseline Regression Model - Cross Validation\n",
    "**Perform tenfold cross validation using the grid search \"best\" parameters and our Capped Linear Regression estimator**\n",
    "* 10-fold cross-validation using the parameters for the top performing model \n",
    "* CAP predictions between 0 and 100% \n",
    "* Evaluate cross-validation results using MAE, MAPE, and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average MAE for all cv folds is: \t\t\t 4.8215\n",
      "The average MAE percentage (MAPE) for all cv folds is: \t 5.4848\n",
      "The average RMSE for all cv folds is: \t\t\t 6.7524\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.157671</td>\n",
       "      <td>5.910517</td>\n",
       "      <td>6.737279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.329242</td>\n",
       "      <td>5.047477</td>\n",
       "      <td>5.516284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.198742</td>\n",
       "      <td>4.918495</td>\n",
       "      <td>6.441173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.904824</td>\n",
       "      <td>5.513290</td>\n",
       "      <td>6.167121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.103980</td>\n",
       "      <td>6.021297</td>\n",
       "      <td>6.777115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.038233</td>\n",
       "      <td>6.513581</td>\n",
       "      <td>9.802383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.599184</td>\n",
       "      <td>5.059766</td>\n",
       "      <td>6.534697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.224444</td>\n",
       "      <td>5.783523</td>\n",
       "      <td>7.572517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.509981</td>\n",
       "      <td>5.359443</td>\n",
       "      <td>6.458367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.149200</td>\n",
       "      <td>4.720193</td>\n",
       "      <td>5.517548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MAE      MAPE      RMSE\n",
       "0  5.157671  5.910517  6.737279\n",
       "1  4.329242  5.047477  5.516284\n",
       "2  4.198742  4.918495  6.441173\n",
       "3  4.904824  5.513290  6.167121\n",
       "4  5.103980  6.021297  6.777115\n",
       "5  6.038233  6.513581  9.802383\n",
       "6  4.599184  5.059766  6.534697\n",
       "7  5.224444  5.783523  7.572517\n",
       "8  4.509981  5.359443  6.458367\n",
       "9  4.149200  4.720193  5.517548"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create CappedLinearRegression predictions between 0 and 100% using the best parameters for our Linear Regression object\n",
    "regEstimator = regGridSearch.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics. \n",
    "EvaluateRegressionEstimator(regEstimator, X_highSchools, Y, cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Four Year Graduation Rate - Support Vector Regression\n",
    "**This model uses Support Vector Machines for regression of continuous variables (SVR). Please see documentation here:\"**\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html\n",
    "* http://scikit-learn.org/stable/modules/svm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed: 43.0min\n",
      "[Parallel(n_jobs=8)]: Done 320 out of 320 | elapsed: 169.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=0, test_size=0.1, train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'kernel': ['rbf', 'linear'], 'C': [0.001, 0.1, 1, 10], 'gamma': [0, 0.1, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a Linear regression object and perform a grid search to find the best parameters\n",
    "from sklearn.svm import SVR\n",
    "reg = SVR()\n",
    "\n",
    "#Set up SVR parameters to test (WARNING: Creates 320 models!!!) \n",
    "costs = [0.001, 0.1, 1, 10]\n",
    "defGamma = 1 / X_highSchools.shape[1]  #This is the default value for the gamma parameter\n",
    "gammas = [defGamma, 0.1, 1, 10]\n",
    "kernels = ['rbf','linear']\n",
    "parameters = {'C': costs, 'gamma' : gammas, 'kernel': kernels}\n",
    "\n",
    "#Create a grid search object using the parameters above\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=reg\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv # KFolds = 10\n",
    "                   , scoring=mae_scorer)\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "regGridSearch.fit(X_highSchools, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=0.001, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0,\n",
       "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the best estimator parameters\n",
    "regGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average MAE for all cv folds is: \t\t\t 4.2322\n",
      "The average MAE percentage (MAPE) for all cv folds is: \t 4.8262\n",
      "The average RMSE for all cv folds is: \t\t\t 5.71\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.317272</td>\n",
       "      <td>5.000740</td>\n",
       "      <td>5.545527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.683116</td>\n",
       "      <td>4.290386</td>\n",
       "      <td>4.815138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.255604</td>\n",
       "      <td>5.034922</td>\n",
       "      <td>6.271977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.477428</td>\n",
       "      <td>4.995918</td>\n",
       "      <td>5.833342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.688041</td>\n",
       "      <td>4.454215</td>\n",
       "      <td>5.165651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.723698</td>\n",
       "      <td>5.096580</td>\n",
       "      <td>6.822188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.400211</td>\n",
       "      <td>4.871065</td>\n",
       "      <td>5.402046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.910904</td>\n",
       "      <td>4.273812</td>\n",
       "      <td>5.073834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.439180</td>\n",
       "      <td>5.276338</td>\n",
       "      <td>6.289764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.426441</td>\n",
       "      <td>4.968011</td>\n",
       "      <td>5.880077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MAE      MAPE      RMSE\n",
       "0  4.317272  5.000740  5.545527\n",
       "1  3.683116  4.290386  4.815138\n",
       "2  4.255604  5.034922  6.271977\n",
       "3  4.477428  4.995918  5.833342\n",
       "4  3.688041  4.454215  5.165651\n",
       "5  4.723698  5.096580  6.822188\n",
       "6  4.400211  4.871065  5.402046\n",
       "7  3.910904  4.273812  5.073834\n",
       "8  4.439180  5.276338  6.289764\n",
       "9  4.426441  4.968011  5.880077"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "#Create a regression estimator with best parameters for cross validation\n",
    "regEstimator = SVR(C=0.001, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
    "                   kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics.\n",
    "EvaluateRegressionEstimator(regEstimator, X_highSchools, Y, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Yhat Max: ', 105.6410251874665)\n"
     ]
    }
   ],
   "source": [
    "#Do we predict graduation rates greater than 100%?\n",
    "regEstimator = SVR(C=0.001, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
    "                   kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
    "\n",
    "regEstimator.fit(X_highSchools, Y)\n",
    "yhat = regEstimator.predict(X_highSchools)\n",
    "print(\"Yhat Max: \", yhat.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Four Year Graduation Rate - Lasso Regression\n",
    "**This model uses Lasso regression (L1 Norm). Please see documentation here:\"**\n",
    "* **Caution!** - See documentation for fit_intercept, normalize, and copy_X. Lasso can over-write your X data!\n",
    "* Lasso may also perform scaling as well.  Please see docs!\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    6.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=0, test_size=0.1, train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=10000,\n",
       "   normalize=True, positive=False, precompute=True, random_state=0,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'warm_start': [True, False], 'alpha': [0.001, 0.1, 1, 10, 20], 'selection': ['cyclic', 'random']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a regression object and perform a grid search to find the best parameters\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "reg = Lasso(fit_intercept=True, normalize=True,copy_X=True\n",
    "          , max_iter=10000, precompute=True, tol=0.0001, random_state=0)\n",
    "\n",
    "#Test parameters \n",
    "alpha = [0.001, 0.1, 1, 10, 20]\n",
    "selection = ['cyclic','random']\n",
    "warm_start = [True, False]\n",
    "parameters = {'alpha': alpha, 'selection': selection, 'warm_start': warm_start}\n",
    "\n",
    "#Create a grid search object using the parameters above\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=reg\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv # KFolds = 10\n",
    "                   , scoring=mae_scorer)\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "regGridSearch.fit(X_highSchools, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.001, copy_X=True, fit_intercept=True, max_iter=10000,\n",
       "   normalize=True, positive=False, precompute=True, random_state=0,\n",
       "   selection='cyclic', tol=0.0001, warm_start=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the best estimator parameters\n",
    "regGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average MAE for all cv folds is: \t\t\t 4.5603\n",
      "The average MAE percentage (MAPE) for all cv folds is: \t 5.1663\n",
      "The average RMSE for all cv folds is: \t\t\t 6.1106\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.087193</td>\n",
       "      <td>5.838551</td>\n",
       "      <td>6.449550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.219906</td>\n",
       "      <td>4.931849</td>\n",
       "      <td>5.417639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.432437</td>\n",
       "      <td>5.088017</td>\n",
       "      <td>6.356763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.554524</td>\n",
       "      <td>5.099317</td>\n",
       "      <td>5.859344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.192217</td>\n",
       "      <td>4.933191</td>\n",
       "      <td>5.482496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.332211</td>\n",
       "      <td>5.739085</td>\n",
       "      <td>8.028462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.936802</td>\n",
       "      <td>5.387179</td>\n",
       "      <td>6.554682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.715811</td>\n",
       "      <td>5.211557</td>\n",
       "      <td>6.182065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.211002</td>\n",
       "      <td>4.991841</td>\n",
       "      <td>5.736473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.920510</td>\n",
       "      <td>4.442602</td>\n",
       "      <td>5.038334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MAE      MAPE      RMSE\n",
       "0  5.087193  5.838551  6.449550\n",
       "1  4.219906  4.931849  5.417639\n",
       "2  4.432437  5.088017  6.356763\n",
       "3  4.554524  5.099317  5.859344\n",
       "4  4.192217  4.933191  5.482496\n",
       "5  5.332211  5.739085  8.028462\n",
       "6  4.936802  5.387179  6.554682\n",
       "7  4.715811  5.211557  6.182065\n",
       "8  4.211002  4.991841  5.736473\n",
       "9  3.920510  4.442602  5.038334"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a regression estimator with best parameters for cross validation\n",
    "regEstimator = regGridSearch.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics.\n",
    "EvaluateRegressionEstimator(regEstimator, X_highSchools, Y, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Yhat Max: ', 106.0026617159198)\n"
     ]
    }
   ],
   "source": [
    "#Do we predict graduation rates greater than 100%?\n",
    "regEstimator = Lasso(alpha=0.001, copy_X=True, fit_intercept=True, max_iter=10000,\n",
    "   normalize=True, positive=False, precompute=True, random_state=0,\n",
    "   selection='cyclic', tol=0.0001, warm_start=True)\n",
    "\n",
    "regEstimator.fit(X_highSchools, Y)\n",
    "yhat = regEstimator.predict(X_highSchools)\n",
    "print(\"Yhat Max: \", yhat.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Four Year Graduation Rate - Ridge Regression\n",
    "**This model uses Ridge regression (L2 Norm). Please see documentation here:\"**\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=8)]: Done 292 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=8)]: Done 360 out of 360 | elapsed:   11.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=0, test_size=0.1, train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=True, random_state=0, solver='auto', tol=0.0001),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'alpha': [0.001, 0.1, 1, 5, 10, 20], 'solver': ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a regression object and perform a grid search to find the best parameters\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "reg = Ridge(fit_intercept=True, normalize=True,copy_X=True\n",
    "          , max_iter=1000, tol=0.0001, random_state=0)\n",
    "\n",
    "#Test parameters \n",
    "alpha = [0.001, 0.1, 1, 5, 10, 20]\n",
    "solver = [ 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "parameters = {'alpha': alpha, 'solver': solver}\n",
    "\n",
    "#Create a grid search object using the parameters above\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=reg\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv # KFolds = 10\n",
    "                   , scoring=mae_scorer)\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "regGridSearch.fit(X_highSchools, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=1000, normalize=True,\n",
       "   random_state=0, solver='lsqr', tol=0.0001)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the best estimator parameters\n",
    "regGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average MAE for all cv folds is: \t\t\t 4.1336\n",
      "The average MAE percentage (MAPE) for all cv folds is: \t 4.7528\n",
      "The average RMSE for all cv folds is: \t\t\t 5.4062\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.706611</td>\n",
       "      <td>5.464584</td>\n",
       "      <td>5.855681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.777249</td>\n",
       "      <td>4.489016</td>\n",
       "      <td>5.005438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.957620</td>\n",
       "      <td>4.704205</td>\n",
       "      <td>5.787421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.365847</td>\n",
       "      <td>4.905169</td>\n",
       "      <td>5.582526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.113197</td>\n",
       "      <td>4.980211</td>\n",
       "      <td>5.685719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.410480</td>\n",
       "      <td>4.822773</td>\n",
       "      <td>5.544850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.298392</td>\n",
       "      <td>4.801208</td>\n",
       "      <td>5.328388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.965322</td>\n",
       "      <td>4.343607</td>\n",
       "      <td>4.888841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.835697</td>\n",
       "      <td>4.602738</td>\n",
       "      <td>5.426579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.906017</td>\n",
       "      <td>4.414916</td>\n",
       "      <td>4.956498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MAE      MAPE      RMSE\n",
       "0  4.706611  5.464584  5.855681\n",
       "1  3.777249  4.489016  5.005438\n",
       "2  3.957620  4.704205  5.787421\n",
       "3  4.365847  4.905169  5.582526\n",
       "4  4.113197  4.980211  5.685719\n",
       "5  4.410480  4.822773  5.544850\n",
       "6  4.298392  4.801208  5.328388\n",
       "7  3.965322  4.343607  4.888841\n",
       "8  3.835697  4.602738  5.426579\n",
       "9  3.906017  4.414916  4.956498"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a regression estimator with best parameters for cross validation\n",
    "regEstimator = regGridSearch.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics.\n",
    "EvaluateRegressionEstimator(regEstimator, X_highSchools, Y, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Yhat Max: ', 105.23151401651583)\n"
     ]
    }
   ],
   "source": [
    "#Do we predict graduation rates greater than 100%?\n",
    "regEstimator = Ridge(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
    "   normalize=True, random_state=0, solver='saga', tol=0.0001)\n",
    "\n",
    "regEstimator.fit(X_highSchools, Y)\n",
    "yhat = regEstimator.predict(X_highSchools)\n",
    "print(\"Yhat Max: \", yhat.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Four Year Graduation Rate - Elastic Net Regression\n",
    "**This model uses Elastic Net Regression (L1 and L2 Norm mixing). Please see documentation here:\"**\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=8)]: Done 539 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=8)]: Done 960 out of 960 | elapsed:   10.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=0, test_size=0.1, train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=10000, normalize=True, positive=False, precompute=True,\n",
       "      random_state=0, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'warm_start': [True, False], 'l1_ratio': [0.001, 0.01, 0.1, 0.5, 0.75, 1], 'selection': ['cyclic', 'random'], 'alpha': [0.001, 0.1, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a regression object and perform a grid search to find the best parameters\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "reg = ElasticNet(fit_intercept=True, normalize=True, precompute=True, copy_X=True\n",
    "          , max_iter=10000, tol=0.0001, random_state=0)\n",
    " \n",
    "#Test parameters\n",
    "l1_ratio = [0.001, 0.01, 0.1, 0.5, 0.75, 1]\n",
    "alpha = [0.001, 0.1, 1, 10]\n",
    "selection = ['cyclic','random']\n",
    "warm_start = [True, False]\n",
    "parameters = {'l1_ratio': l1_ratio, 'alpha': alpha, 'selection': selection, 'warm_start': warm_start}\n",
    "\n",
    "#Create a grid search object using the parameters above\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=reg\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv # KFolds = 10\n",
    "                   , scoring=mae_scorer)\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "regGridSearch.fit(X_highSchools, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.001, copy_X=True, fit_intercept=True, l1_ratio=0.001,\n",
       "      max_iter=10000, normalize=True, positive=False, precompute=True,\n",
       "      random_state=0, selection='random', tol=0.0001, warm_start=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the best estimator parameters\n",
    "regGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average MAE for all cv folds is: \t\t\t 4.12\n",
      "The average MAE percentage (MAPE) for all cv folds is: \t 4.7168\n",
      "The average RMSE for all cv folds is: \t\t\t 5.356\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.729185</td>\n",
       "      <td>5.481715</td>\n",
       "      <td>5.888101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.702081</td>\n",
       "      <td>4.386866</td>\n",
       "      <td>4.918881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.951854</td>\n",
       "      <td>4.618891</td>\n",
       "      <td>5.518204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.347705</td>\n",
       "      <td>4.873549</td>\n",
       "      <td>5.647332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.069026</td>\n",
       "      <td>4.869714</td>\n",
       "      <td>5.316510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.401107</td>\n",
       "      <td>4.818437</td>\n",
       "      <td>5.648600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.313902</td>\n",
       "      <td>4.811362</td>\n",
       "      <td>5.435623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.162980</td>\n",
       "      <td>4.572804</td>\n",
       "      <td>5.129820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.710824</td>\n",
       "      <td>4.421984</td>\n",
       "      <td>5.157805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.811556</td>\n",
       "      <td>4.312315</td>\n",
       "      <td>4.899614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MAE      MAPE      RMSE\n",
       "0  4.729185  5.481715  5.888101\n",
       "1  3.702081  4.386866  4.918881\n",
       "2  3.951854  4.618891  5.518204\n",
       "3  4.347705  4.873549  5.647332\n",
       "4  4.069026  4.869714  5.316510\n",
       "5  4.401107  4.818437  5.648600\n",
       "6  4.313902  4.811362  5.435623\n",
       "7  4.162980  4.572804  5.129820\n",
       "8  3.710824  4.421984  5.157805\n",
       "9  3.811556  4.312315  4.899614"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a regression estimator with best parameters for cross validation\n",
    "regEstimator = regGridSearch.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics.\n",
    "EvaluateRegressionEstimator(regEstimator, X_highSchools, Y, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Yhat Max: ', 105.35126738890227)\n"
     ]
    }
   ],
   "source": [
    "#Do we predict graduation rates greater than 100%?\n",
    "regEstimator = ElasticNet(alpha=0.001, copy_X=True, fit_intercept=True, l1_ratio=0.75,\n",
    "      max_iter=10000, normalize=True, positive=False, precompute=True,\n",
    "      random_state=0, selection='cyclic', tol=0.0001, warm_start=True)\n",
    "\n",
    "regEstimator.fit(X_highSchools, Y)\n",
    "yhat = regEstimator.predict(X_highSchools)\n",
    "print(\"Yhat Max: \", yhat.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Four Year Graduation Rate - Logit Regression using Python \n",
    "**This model uses a custom Logit model based on transformations of the Linear Regression object. Please see documentation here:\"**\n",
    "* https://stackoverflow.com/questions/33845539/modelling-probabilities-in-a-regularized-logistic-regression-model-in-python\n",
    "* https://stackoverflow.com/questions/44234682/how-to-use-sklearn-when-target-variable-is-a-proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "class LogitRegression(LinearRegression):\n",
    "\n",
    "    def fit(self, x, p):\n",
    "        p[p==0] = 0.009    #0.1111111111111111 \n",
    "        p[p==1] = 0.991    #0.9999999999999999  big precision seems to kill MAE scores here?\n",
    "        #e = 0.0000000000000001\n",
    "        #p = p * e + 0.5 * e                    This technique was really bad too. \n",
    "        p = np.asarray(p)\n",
    "        y = np.log(p / (1 - p))\n",
    "        return super(LogitRegression, self).fit(x, y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        y = super(LogitRegression, self).predict(x)\n",
    "        yhat = 1 / (np.exp(-y) + 1)\n",
    "        yhat[yhat <= 0.009] = 0\n",
    "        yhat[yhat >= 0.991] = 1\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:17: RuntimeWarning: overflow encountered in exp\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=0, test_size=0.1, train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=LogitRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'normalize': (True, False), 'fit_intercept': (True, False)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert y to a proability \n",
    "Y = Y_4yr_Gr / 100\n",
    "\n",
    "#Create a Linear Regression object and perform a grid search to find the best parameters\n",
    "linreg = LogitRegression()\n",
    "parameters = {'normalize':(True,False), 'fit_intercept':(True,False)}\n",
    "\n",
    "#Create a grid search object using the  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=linreg\n",
    "                   #, n_jobs=8 # jobs to run in parallel (This breaks the custom estimators for some reason!)\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv # KFolds = 10\n",
    "                   , scoring=mae_scorer)\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "regGridSearch.fit(X_highSchools, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogitRegression(copy_X=True, fit_intercept=False, n_jobs=1, normalize=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the best estimator parameters\n",
    "regGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since we converted our response variable to a percentile MAE and RMSE results below must be mutiplied by 100.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average MAE for all cv folds is: \t\t\t 0.061046\n",
      "The average MAE percentage (MAPE) for all cv folds is: \t 7.0723\n",
      "The average RMSE for all cv folds is: \t\t\t 0.09814\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.061435</td>\n",
       "      <td>6.994760</td>\n",
       "      <td>0.092560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.051566</td>\n",
       "      <td>6.101060</td>\n",
       "      <td>0.066119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.064954</td>\n",
       "      <td>8.024552</td>\n",
       "      <td>0.113613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.047756</td>\n",
       "      <td>5.399603</td>\n",
       "      <td>0.061098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.067247</td>\n",
       "      <td>8.283215</td>\n",
       "      <td>0.113218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.083937</td>\n",
       "      <td>9.182917</td>\n",
       "      <td>0.171557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.054739</td>\n",
       "      <td>6.067264</td>\n",
       "      <td>0.095184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.073480</td>\n",
       "      <td>8.300669</td>\n",
       "      <td>0.107320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.057234</td>\n",
       "      <td>6.780125</td>\n",
       "      <td>0.100042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.048110</td>\n",
       "      <td>5.589159</td>\n",
       "      <td>0.060692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MAE      MAPE      RMSE\n",
       "0  0.061435  6.994760  0.092560\n",
       "1  0.051566  6.101060  0.066119\n",
       "2  0.064954  8.024552  0.113613\n",
       "3  0.047756  5.399603  0.061098\n",
       "4  0.067247  8.283215  0.113218\n",
       "5  0.083937  9.182917  0.171557\n",
       "6  0.054739  6.067264  0.095184\n",
       "7  0.073480  8.300669  0.107320\n",
       "8  0.057234  6.780125  0.100042\n",
       "9  0.048110  5.589159  0.060692"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create CappedLinearRegression predictions between 0 and 100% using the best parameters for our Linear Regression object\n",
    "regEstimator = regGridSearch.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics. \n",
    "EvaluateRegressionEstimator(regEstimator, X_highSchools, Y, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Change Y back to normal\n",
    "Y = Y_4yr_Gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Four Year Graduation Rate - Regression using the Random Forest Regressor \n",
    "**This model uses a custom Logit model using the Random Forest Regressor. Please see documentation here: **\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor\n",
    "* https://www.analyticsvidhya.com/blog/2015/06/tuning-random-forest-model/\n",
    "* https://www.kaggle.com/general/4092"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed: 12.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=0, test_size=0.1, train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'n_jobs': [8], 'min_samples_leaf': [10, 25, 50, 75], 'n_estimators': [500], 'random_state': [0], 'criterion': ['mae'], 'min_samples_split': [2, 3, 4, 5, 6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a Linear Regression object and perform a grid search to find the best parameters\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "linreg = RandomForestRegressor()\n",
    "parameters = { 'min_samples_split':[2,3,4,5,6]\n",
    "              ,'n_estimators' : [500]\n",
    "              ,'min_samples_leaf': [10, 25, 50, 75]\n",
    "              ,'criterion': ['mae']\n",
    "              ,'n_jobs':[8] \n",
    "              ,'random_state': [0]\n",
    "             }\n",
    "\n",
    "#Create a grid search object using the  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=linreg\n",
    "                   , n_jobs=8 \n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv # KFolds = 10\n",
    "                   , scoring=mae_scorer)\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "regGridSearch.fit(X_highSchools, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=10, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=8,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the best estimator parameters\n",
    "regGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average MAE for all cv folds is: \t\t\t 4.0282\n",
      "The average MAE percentage (MAPE) for all cv folds is: \t 4.6919\n",
      "The average RMSE for all cv folds is: \t\t\t 5.5681\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.304709</td>\n",
       "      <td>5.039537</td>\n",
       "      <td>5.449514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.239134</td>\n",
       "      <td>5.025416</td>\n",
       "      <td>5.543658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.183148</td>\n",
       "      <td>5.100490</td>\n",
       "      <td>6.871940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.115039</td>\n",
       "      <td>4.654176</td>\n",
       "      <td>5.442268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.618409</td>\n",
       "      <td>4.556457</td>\n",
       "      <td>6.058206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.995116</td>\n",
       "      <td>4.379159</td>\n",
       "      <td>5.216010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.213189</td>\n",
       "      <td>4.720733</td>\n",
       "      <td>5.359561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.549514</td>\n",
       "      <td>3.934088</td>\n",
       "      <td>4.584986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.135595</td>\n",
       "      <td>5.055928</td>\n",
       "      <td>6.279551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.927850</td>\n",
       "      <td>4.453390</td>\n",
       "      <td>4.875249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MAE      MAPE      RMSE\n",
       "0  4.304709  5.039537  5.449514\n",
       "1  4.239134  5.025416  5.543658\n",
       "2  4.183148  5.100490  6.871940\n",
       "3  4.115039  4.654176  5.442268\n",
       "4  3.618409  4.556457  6.058206\n",
       "5  3.995116  4.379159  5.216010\n",
       "6  4.213189  4.720733  5.359561\n",
       "7  3.549514  3.934088  4.584986\n",
       "8  4.135595  5.055928  6.279551\n",
       "9  3.927850  4.453390  4.875249"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create CappedLinearRegression predictions between 0 and 100% using the best parameters for our Linear Regression object\n",
    "regEstimator = regGridSearch.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics. \n",
    "EvaluateRegressionEstimator(regEstimator, X_highSchools, Y, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Yhat Max: ', 100.0)\n"
     ]
    }
   ],
   "source": [
    "#Do we predict graduation rates greater than 100%?\n",
    "regEstimator = regGridSearch.best_estimator_\n",
    "\n",
    "regEstimator.fit(X_highSchools, Y)\n",
    "yhat = regEstimator.predict(X_highSchools)\n",
    "print(\"Yhat Max: \", yhat.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Four Year Graduation Rate - Regression using the Extra Trees Regressor \n",
    "**This model uses a custom Logit model using the Random Forest Regressor. Please see documentation here: **\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:  8.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=0, test_size=0.1, train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
       "          max_features='auto', max_leaf_nodes=None,\n",
       "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "          min_samples_leaf=1, min_samples_split=2,\n",
       "          min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "          oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'n_jobs': [8], 'min_samples_leaf': [10, 25, 50, 75], 'n_estimators': [500], 'random_state': [0], 'criterion': ['mae'], 'min_samples_split': [2, 3, 4, 5, 6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a Linear Regression object and perform a grid search to find the best parameters\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "linreg = ExtraTreesRegressor()\n",
    "parameters = { 'min_samples_split':[2,3,4,5,6]\n",
    "              ,'n_estimators' : [500]\n",
    "              ,'min_samples_leaf': [10, 25, 50, 75]\n",
    "              ,'criterion': ['mae']\n",
    "              ,'n_jobs':[8] \n",
    "              ,'random_state': [0]\n",
    "             }\n",
    "\n",
    "#Create a grid search object using the  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=linreg\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv # KFolds = 10\n",
    "                   , scoring=mae_scorer)\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "regGridSearch.fit(X_highSchools, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor(bootstrap=False, criterion='mae', max_depth=None,\n",
       "          max_features='auto', max_leaf_nodes=None,\n",
       "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "          min_samples_leaf=10, min_samples_split=2,\n",
       "          min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=8,\n",
       "          oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the best estimator parameters\n",
    "regGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average MAE for all cv folds is: \t\t\t 4.0667\n",
      "The average MAE percentage (MAPE) for all cv folds is: \t 4.7584\n",
      "The average RMSE for all cv folds is: \t\t\t 5.7712\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.495298</td>\n",
       "      <td>5.240008</td>\n",
       "      <td>5.560150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.846000</td>\n",
       "      <td>4.608120</td>\n",
       "      <td>5.327770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.186380</td>\n",
       "      <td>5.191555</td>\n",
       "      <td>7.460197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.187095</td>\n",
       "      <td>4.737413</td>\n",
       "      <td>5.510047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.939982</td>\n",
       "      <td>4.982738</td>\n",
       "      <td>6.735846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.965732</td>\n",
       "      <td>4.337137</td>\n",
       "      <td>5.276172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.160607</td>\n",
       "      <td>4.670700</td>\n",
       "      <td>5.238482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.590666</td>\n",
       "      <td>3.992865</td>\n",
       "      <td>4.771941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.263811</td>\n",
       "      <td>5.264979</td>\n",
       "      <td>6.882225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.031520</td>\n",
       "      <td>4.558070</td>\n",
       "      <td>4.948689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MAE      MAPE      RMSE\n",
       "0  4.495298  5.240008  5.560150\n",
       "1  3.846000  4.608120  5.327770\n",
       "2  4.186380  5.191555  7.460197\n",
       "3  4.187095  4.737413  5.510047\n",
       "4  3.939982  4.982738  6.735846\n",
       "5  3.965732  4.337137  5.276172\n",
       "6  4.160607  4.670700  5.238482\n",
       "7  3.590666  3.992865  4.771941\n",
       "8  4.263811  5.264979  6.882225\n",
       "9  4.031520  4.558070  4.948689"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create CappedLinearRegression predictions between 0 and 100% using the best parameters for our Linear Regression object\n",
    "regEstimator = regGridSearch.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics. \n",
    "EvaluateRegressionEstimator(regEstimator, X_highSchools, Y, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Yhat Max: ', 100.0)\n"
     ]
    }
   ],
   "source": [
    "#Do we predict graduation rates greater than 100%?\n",
    "regEstimator = regGridSearch.best_estimator_\n",
    "\n",
    "regEstimator.fit(X_highSchools, Y)\n",
    "yhat = regEstimator.predict(X_highSchools)\n",
    "print(\"Yhat Max: \", yhat.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Four Year Graduation Rate - Multilayer Perceptron Regression \n",
    "**This model uses a neural network for regression. Please see documentation here: **\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html\n",
    "* https://stackoverflow.com/questions/41069905/trouble-fitting-simple-data-with-mlpregressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=8)]: Done  60 out of  60 | elapsed:   54.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=0, test_size=0.1, train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'power_t': [0.5], 'random_state': [0], 'learning_rate_init': [0.001], 'max_iter': [1000], 'hidden_layer_sizes': [200], 'alpha': [0.001], 'activation': ['logistic'], 'solver': ['sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'batch_size': ['auto']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a Linear Regression object and perform a grid search to find the best parameters\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "linreg = MLPRegressor()\n",
    "parameters = { 'activation':['logistic']\n",
    "              ,'hidden_layer_sizes' : [200]\n",
    "              ,'solver': ['sgd','adam']\n",
    "              ,'alpha': [0.001]\n",
    "              ,'batch_size':['auto'] \n",
    "              ,'random_state': [0]\n",
    "              ,'learning_rate': ['constant', 'invscaling', 'adaptive']\n",
    "              ,'learning_rate_init':[0.001]\n",
    "              ,'power_t':[0.5]\n",
    "              ,'max_iter':[1000]\n",
    "             }\n",
    "\n",
    "#Create a grid search object using the  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=linreg\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv # KFolds = 10\n",
    "                   , scoring=mae_scorer)\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "regGridSearch.fit(X_highSchools, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='logistic', alpha=0.001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=200, learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the best estimator parameters\n",
    "regGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average MAE for all cv folds is: \t\t\t 6.3449\n",
      "The average MAE percentage (MAPE) for all cv folds is: \t 7.1447\n",
      "The average RMSE for all cv folds is: \t\t\t 7.875\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.738029</td>\n",
       "      <td>7.619889</td>\n",
       "      <td>7.994531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.296849</td>\n",
       "      <td>7.363970</td>\n",
       "      <td>7.814990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.808859</td>\n",
       "      <td>6.726731</td>\n",
       "      <td>7.494670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.630901</td>\n",
       "      <td>7.240898</td>\n",
       "      <td>8.407064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.600886</td>\n",
       "      <td>7.707778</td>\n",
       "      <td>8.527891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.626161</td>\n",
       "      <td>7.134561</td>\n",
       "      <td>7.896361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.831238</td>\n",
       "      <td>7.476419</td>\n",
       "      <td>8.078016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.700272</td>\n",
       "      <td>6.175055</td>\n",
       "      <td>6.972898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.078219</td>\n",
       "      <td>7.149038</td>\n",
       "      <td>8.074822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.137688</td>\n",
       "      <td>6.852602</td>\n",
       "      <td>7.489027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MAE      MAPE      RMSE\n",
       "0  6.738029  7.619889  7.994531\n",
       "1  6.296849  7.363970  7.814990\n",
       "2  5.808859  6.726731  7.494670\n",
       "3  6.630901  7.240898  8.407064\n",
       "4  6.600886  7.707778  8.527891\n",
       "5  6.626161  7.134561  7.896361\n",
       "6  6.831238  7.476419  8.078016\n",
       "7  5.700272  6.175055  6.972898\n",
       "8  6.078219  7.149038  8.074822\n",
       "9  6.137688  6.852602  7.489027"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create CappedLinearRegression predictions between 0 and 100% using the best parameters for our Linear Regression object\n",
    "regEstimator = regGridSearch.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics. \n",
    "EvaluateRegressionEstimator(regEstimator, X_highSchools, Y, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Yhat Max: ', 88.99716413494296)\n"
     ]
    }
   ],
   "source": [
    "#Do we predict graduation rates greater than 100%?\n",
    "regEstimator = regGridSearch.best_estimator_\n",
    "\n",
    "regEstimator.fit(X_highSchools, Y)\n",
    "yhat = regEstimator.predict(X_highSchools)\n",
    "print(\"Yhat Max: \", yhat.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Four Year Graduation Rate - Logit Regression using GLM and R \n",
    "**This model uses GLM and R. Please see documentation here:\"**\n",
    "* **WARNING** - You must have the R Kernel installed to use this code!!!\n",
    "* Logit Regression is performed on graduation rates scaled in the range 0 to 1\n",
    "* The GLM package in R uses the parameter Family=binomial(link='logit') to perform this regression.\n",
    "* It may be possible to use Rmagic and Rpy2 from within Python to accomplish the same tasks.  However, this is not yet supported on Windows.  The code below works on Mac or Windows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing and training fold data are first written out to disk as .csv files using Python.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write our test / train folds out to disk so we may use them in R \n",
    "foldct = 1\n",
    "dirPath = \"D:/BenepactLLC/Belk/NC_Report_Card_Data/February 2018 Report/Datasets/\"\n",
    "\n",
    "for train, test in cv.split(schData):\n",
    "    testFileName = dirPath + 'TestFold' + str(foldct) + '.csv'\n",
    "    trainFileName = dirPath + 'TrainFold' + str(foldct) + '.csv'\n",
    "    schData.iloc[test].to_csv(testFileName, sep=',', index=False)\n",
    "    schData.iloc[train].to_csv(trainFileName, sep=',', index=False)\n",
    "    foldct = foldct + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing and training fold data are read in from .csv files using R.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\"The max value predicted is: 99.6455187331921\""
      ],
      "text/latex": [
       "\"The max value predicted is: 99.6455187331921\""
      ],
      "text/markdown": [
       "\"The max value predicted is: 99.6455187331921\""
      ],
      "text/plain": [
       "[1] \"The max value predicted is: 99.6455187331921\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\"The average MAE for all cv folds is: 6.33766411785571\""
      ],
      "text/latex": [
       "\"The average MAE for all cv folds is: 6.33766411785571\""
      ],
      "text/markdown": [
       "\"The average MAE for all cv folds is: 6.33766411785571\""
      ],
      "text/plain": [
       "[1] \"The average MAE for all cv folds is: 6.33766411785571\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\"The average RMSE for all cv folds is: 11.46988539425\""
      ],
      "text/latex": [
       "\"The average RMSE for all cv folds is: 11.46988539425\""
      ],
      "text/markdown": [
       "\"The average RMSE for all cv folds is: 11.46988539425\""
      ],
      "text/plain": [
       "[1] \"The average RMSE for all cv folds is: 11.46988539425\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Package</th><th scope=col>FoldCount</th><th scope=col>MAE</th><th scope=col>RMSE</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>GLM</td><td>44</td><td>6.136212</td><td>9.757559</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>GLM</td><td>44</td><td>5.397666</td><td>7.143312</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>GLM</td><td>44</td><td>7.4721</td><td>15.80928</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>GLM</td><td>44</td><td>5.20695</td><td>7.745486</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>GLM</td><td>44</td><td>6.888822</td><td>12.11713</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>GLM</td><td>44</td><td>7.227467</td><td>14.47816</td></tr>\n",
       "\t<tr><th scope=row>7</th><td>GLM</td><td>44</td><td>5.609856</td><td>9.021769</td></tr>\n",
       "\t<tr><th scope=row>8</th><td>GLM</td><td>44</td><td>7.385392</td><td>16.40233</td></tr>\n",
       "\t<tr><th scope=row>9</th><td>GLM</td><td>44</td><td>5.781938</td><td>9.723755</td></tr>\n",
       "\t<tr><th scope=row>10</th><td>GLM</td><td>44</td><td>6.270238</td><td>12.50008</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       "  & Package & FoldCount & MAE & RMSE\\\\\n",
       "\\hline\n",
       "\t1 & GLM & 44 & 6.136212 & 9.757559\\\\\n",
       "\t2 & GLM & 44 & 5.397666 & 7.143312\\\\\n",
       "\t3 & GLM & 44 & 7.4721 & 15.80928\\\\\n",
       "\t4 & GLM & 44 & 5.20695 & 7.745486\\\\\n",
       "\t5 & GLM & 44 & 6.888822 & 12.11713\\\\\n",
       "\t6 & GLM & 44 & 7.227467 & 14.47816\\\\\n",
       "\t7 & GLM & 44 & 5.609856 & 9.021769\\\\\n",
       "\t8 & GLM & 44 & 7.385392 & 16.40233\\\\\n",
       "\t9 & GLM & 44 & 5.781938 & 9.723755\\\\\n",
       "\t10 & GLM & 44 & 6.270238 & 12.50008\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "   Package FoldCount      MAE      RMSE\n",
       "1      GLM        44 6.136212  9.757559\n",
       "2      GLM        44 5.397666  7.143312\n",
       "3      GLM        44 7.472100 15.809279\n",
       "4      GLM        44 5.206950  7.745486\n",
       "5      GLM        44 6.888822 12.117133\n",
       "6      GLM        44 7.227467 14.478155\n",
       "7      GLM        44 5.609856  9.021769\n",
       "8      GLM        44 7.385392 16.402330\n",
       "9      GLM        44 5.781938  9.723755\n",
       "10     GLM        44 6.270238 12.500076"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#*********************************must switch to the R kernel to run this code!********************************* \n",
    "\n",
    "\n",
    "options(warn=-1)\n",
    "\n",
    "setwd(\"D:/BenepactLLC/Belk/NC_Report_Card_Data/February 2018 Report/Datasets/\")\n",
    "\n",
    "#*************************************************************************************\n",
    "#*********************************Evaluation Scores **********************************\n",
    "#*************************************************************************************\n",
    "\n",
    "#Use RMSE and MAE To evaluate performance\n",
    "#See: https://heuristically.wordpress.com/2013/07/12/calculate-rmse-and-mae-in-r-and-sas/\n",
    "\n",
    "# Function that returns Root Mean Squared Error\n",
    "rmse <- function(error)\n",
    "{\n",
    "    sqrt(mean(error^2))\n",
    "}\n",
    " \n",
    "# Function that returns Mean Absolute Error\n",
    "mae <- function(error)\n",
    "{\n",
    "    mean(abs(error))\n",
    "}\n",
    "\n",
    "#*************************************************************************************\n",
    "#*********************************10 Fold CV******************************************\n",
    "#*************************************************************************************\n",
    "tenFoldResults<-NULL\n",
    "drop <- c(\"Graduation_Rate_5_Yr\")\n",
    "y <- c(\"Graduation_Rate4_Yr\")\n",
    "\n",
    "#Perform 10 fold cross validation\n",
    "for(i in 1:10){\n",
    "    #Get file paths\n",
    "    testFile <- paste(c(\"TestFold\", i, \".csv\"), collapse = \"\") \n",
    "    trainFile <- paste(c(\"TrainFold\", i, \".csv\"), collapse = \"\") \n",
    "\n",
    "    #Read in files for each fold \n",
    "    testData <- read.csv(testFile,header=T)\n",
    "    trainData <- read.csv(trainFile,header=T)\n",
    "    \n",
    "    #Remove 5 year graduation rate\n",
    "    testData <- testData[ , !(names(testData) %in% drop)]\n",
    "    trainData <- trainData[ , !(names(trainData) %in% drop)]\n",
    "    \n",
    "    #Scale 4 year graduation rate 0 to 1 binomial(link='logit')\n",
    "    testData[ , y] <- testData[ , y] / 100\n",
    "    trainData[ , y] <- trainData[ , y] / 100\n",
    "    \n",
    "    #Train glm model \n",
    "    model <- glm(Graduation_Rate4_Yr ~.,family=binomial(link='logit'),data=trainData)\n",
    "    yhat <- predict(model,newdata=testData[ , !(names(testData) %in% y)],type='response')\n",
    "\n",
    "    #Get correct answers for predictions\n",
    "    actual <- testData[ , y]\n",
    "    \n",
    "    #Convert y and yhat graduation rates back to normal percentage scale\n",
    "    actual <- actual * 100 \n",
    "    yhat <- yhat * 100 \n",
    "    \n",
    "    #Calcuate our errors\n",
    "    error = actual - yhat\n",
    "    \n",
    "    #Capture results in a dataframe\n",
    "    tenFoldResults <- rbind(tenFoldResults,\n",
    "    data.frame(Package='GLM'\n",
    "              ,FoldCount= length(yhat) \n",
    "              ,MAE=mae(error)\n",
    "              ,RMSE=rmse(error)\n",
    "              )\n",
    "    )\n",
    "}\n",
    "\n",
    "paste(c(\"The max value predicted is:\", max(yhat)), collapse = \" \") \n",
    "paste(c(\"The average MAE for all cv folds is:\", mean(tenFoldResults[,c('MAE')])), collapse = \" \") \n",
    "paste(c(\"The average RMSE for all cv folds is:\", mean(tenFoldResults[,c('RMSE')])), collapse = \" \") \n",
    "tenFoldResults\n",
    "\n",
    "#Turn R warnings back on \n",
    "options(warn=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Scaled Data Test\n",
    "**Test the top performing model using scaled data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Scale dataset converting to standard normally distributed data \n",
    "# (e.g. Gaussian with 0 mean and unit variance).\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Fit to data for scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_highSchools)\n",
    "\n",
    "#Transform training data to z-scores\n",
    "#This makes our model's coefficients take on the same scale for accurate feature importance analisys \n",
    "X_highSchools_Scl = scaler.transform(X_highSchools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average MAE for all cv folds is: \t\t\t 4.0291\n",
      "The average MAE percentage (MAPE) for all cv folds is: \t 4.693\n",
      "The average RMSE for all cv folds is: \t\t\t 5.5689\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.304777</td>\n",
       "      <td>5.039748</td>\n",
       "      <td>5.449990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.240473</td>\n",
       "      <td>5.026917</td>\n",
       "      <td>5.543850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.183598</td>\n",
       "      <td>5.100968</td>\n",
       "      <td>6.872097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.115209</td>\n",
       "      <td>4.654334</td>\n",
       "      <td>5.443303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.619791</td>\n",
       "      <td>4.558120</td>\n",
       "      <td>6.059438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.995886</td>\n",
       "      <td>4.380029</td>\n",
       "      <td>5.216795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.214059</td>\n",
       "      <td>4.721626</td>\n",
       "      <td>5.359384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.552023</td>\n",
       "      <td>3.936899</td>\n",
       "      <td>4.588629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.137482</td>\n",
       "      <td>5.058067</td>\n",
       "      <td>6.280511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.927705</td>\n",
       "      <td>4.453134</td>\n",
       "      <td>4.874904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MAE      MAPE      RMSE\n",
       "0  4.304777  5.039748  5.449990\n",
       "1  4.240473  5.026917  5.543850\n",
       "2  4.183598  5.100968  6.872097\n",
       "3  4.115209  4.654334  5.443303\n",
       "4  3.619791  4.558120  6.059438\n",
       "5  3.995886  4.380029  5.216795\n",
       "6  4.214059  4.721626  5.359384\n",
       "7  3.552023  3.936899  4.588629\n",
       "8  4.137482  5.058067  6.280511\n",
       "9  3.927705  4.453134  4.874904"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Create predictions between 0 and 100% using the best parameters for our Regression object\n",
    "regEstimator = RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=None,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=10, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=8,\n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics. \n",
    "EvaluateRegressionEstimator(regEstimator, X_highSchools_Scl, Y_4yr_Gr, cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regression Feature Importance\n",
    "The top performing model was Random Forest Regression.  Please see the following documentation:\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "* http://blog.datadive.net/selecting-good-features-part-iii-random-forests/\n",
    "\n",
    "**Create one final model using all of the scaled training data for evaluating feature importance.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=10, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=8,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Create predictions between 0 and 100% using the best parameters for our Regression object\n",
    "regEstimator = RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=None,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=10, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=8,\n",
    "           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "#Fit the model using all of the scaled training data\n",
    "regEstimator.fit(X_highSchools, Y_4yr_Gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the model's feature importances and names into a dataframe sorted by importance\n",
    "weights = regEstimator.feature_importances_ \n",
    "feature_names = X_highSchools.columns\n",
    "linreg_ft_imp_df = pd.DataFrame({'feature_names':feature_names, 'weights':weights, 'absolute_weights': np.abs(weights)})\n",
    "linreg_ft_imp_df.sort_values(by='absolute_weights', inplace=True, ascending=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABCQAAAKXCAYAAABaGJvoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCSIiIiIiIiIyuP8H3JK7wqEkdXQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe20a630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Examine categorical variables of interest  \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Plot the model's feature importances\n",
    "# REFERENCE:  Eric Larson, https://github.com/eclarson/DataMiningNotebooks\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "wt_plt_df = linreg_ft_imp_df.head(10)\n",
    "\n",
    "weights = pd.Series(wt_plt_df['weights'].values,index=wt_plt_df['feature_names'])\n",
    "ax = weights.plot(kind='bar', figsize=(18,8))\n",
    "\n",
    "ax.set_title(\"Top Features\")\n",
    "ax.set_ylabel(\"Feature Importance\")\n",
    "ax.set_xlabel(\"Feature Names\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

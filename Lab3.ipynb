{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: CRISP-DM Capstone\n",
    "## Association Rule Mining, Clustering, or Collaborative Filtering\n",
    "\n",
    "### Ryan Bass, Brett Benefield, Cho Kim, Nicole Wittlin\n",
    "\n",
    "<a id=\"top\"></a>\n",
    "## Contents\n",
    "* Business Understanding\n",
    "* Data Understanding\n",
    "    * <a href=\"#data1\">Data Understanding 1</a>\n",
    "    * <a href=\"#data2\">Data Understanding 2</a>\n",
    "* Modeling and Evaluation\n",
    "    * <a href=\"#Model1\">Train and Adjust Parameters</a>\n",
    "    * <a href=\"#Model2\">Evaluate and Compare</a>\n",
    "    * <a href=\"#Model3\">Visualize Results</a>\n",
    "    * <a href=\"#Model4\">Summarize the Ramifications</a>\n",
    "* <a href=\"#Deployment\">Deployment</a>\n",
    "* <a href=\"#Exceptional\">Exceptional Work</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yellowbrick as yb\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from sklearn import metrics as mt\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectFromModel, SelectPercentile, f_regression, mutual_info_regression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, accuracy_score, f1_score, roc_auc_score, mean_absolute_error, make_scorer, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler, Binarizer, scale\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC, SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression, SGDClassifier, RidgeClassifier, LinearRegression\n",
    "from sklearn.linear_model import Ridge, Lasso, LassoCV\n",
    "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, StratifiedShuffleSplit, StratifiedKFold, GridSearchCV, cross_validate, RandomizedSearchCV\n",
    "from yellowbrick.classifier import ClassificationReport, ConfusionMatrix, ClassPredictionError, ROCAUC\n",
    "from yellowbrick.features import Rank1D, Rank2D, RFECV\n",
    "from yellowbrick.features.importances import FeatureImportances\n",
    "from yellowbrick.model_selection import ValidationCurve, LearningCurve\n",
    "from yellowbrick.regressor import PredictionError, ResidualsPlot\n",
    "from yellowbrick.regressor.alphas import AlphaSelection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slack Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'slackclient'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f3d70c1f35e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# I also need to add your name and unique identifier to the dictionary userID below\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mslackclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSlackClient\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdotenv\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_dotenv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'slackclient'"
     ]
    }
   ],
   "source": [
    "# Some setup is required before you can use this because token must be kept private\n",
    "# I also need to add your name and unique identifier to the dictionary userID below\n",
    "import os\n",
    "from slackclient import SlackClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "userID = {\"brett\": \"UAN6UQEVC\", \"ryan\": \"UALUD69AB\"}\n",
    "\n",
    "#slackToken = os.environ[\"SLACK_BOT_TOKEN\"]\n",
    "#sc = SlackClient(slackToken)\n",
    "\n",
    "def sendSlackMessage(msg, user):\n",
    "    result = sc.api_call(\n",
    "    \"chat.postMessage\",\n",
    "    channel=userID[user.lower()],\n",
    "    text=msg)\n",
    "    \n",
    "    if (not result['ok']):\n",
    "        print(\"Error: {}\".format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supporting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://medium.com/@aneesha/visualising-top-features-in-linear-svm-with-scikit-learn-and-matplotlib-3454ab18a14d\n",
    "def plot_coefficients(classifier, feature_names, top_features=20):\n",
    "    coef = classifier.coef_.ravel()\n",
    "    top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
    "    top_negative_coefficients = np.argsort(coef)[:top_features]\n",
    "    top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
    "    # create plot\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    colors = [\"red\" if c < 0 else \"blue\" for c in coef[top_coefficients]]\n",
    "    plt.bar(np.arange(2 * top_features), coef[top_coefficients], color=colors)\n",
    "    feature_names = np.array(feature_names)\n",
    "    plt.xticks(np.arange(1, 1 + 2 * top_features), feature_names[top_coefficients], rotation=60, ha=\"right\")\n",
    "    plt.show()\n",
    "    \n",
    "def getTopCoefficients(classifier, feature_names, top_features=20):\n",
    "    coef = classifier.coef_.ravel()\n",
    "    top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
    "    top_negative_coefficients = np.argsort(coef)[:top_features]\n",
    "    top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
    "    feature_names = np.array(feature_names)\n",
    "    return feature_names[top_coefficients]\n",
    "\n",
    "# Source: https://stackoverflow.com/questions/39812885/retain-feature-names-after-scikit-feature-selection\n",
    "def percentile_threshold_selector(data, percent=10):\n",
    "    selector = SelectPercentile(f_classif, percentile = percent)\n",
    "    selector.fit(data)\n",
    "    return data[data.columns[selector.get_support(indices=True)]]\n",
    "\n",
    "def scale_data(data):\n",
    "    temp = scaler.fit(data)\n",
    "    data = pd.DataFrame(temp, columns = data.columns)\n",
    "    return data\n",
    "\n",
    "# https://stackoverflow.com/questions/17778394/list-highest-correlation-pairs-from-a-large-correlation-matrix-in-pandas\n",
    "def get_redundant_pairs(df):\n",
    "    '''Get diagonal and lower triangular pairs of correlation matrix'''\n",
    "    pairs_to_drop = set()\n",
    "    cols = df.columns\n",
    "    for i in range(0, df.shape[1]):\n",
    "        for j in range(0, i+1):\n",
    "            pairs_to_drop.add((cols[i], cols[j]))\n",
    "    return pairs_to_drop\n",
    "\n",
    "def get_top_abs_correlations(df, n=5):\n",
    "    au_corr = df.corr().abs().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr[0:n]\n",
    "\n",
    "# rmse, mape functions take from :https://github.com/jakemdrew/EducationDataNC/blob/master/Other%20Projects/iPython%20Notebooks/Machine%20Learning/High%20School%20Minority%20Percentage%20February%202018.ipynb\n",
    "#Use mean absolute error (MAE) to score the regression models created \n",
    "#(the scale of MAE is identical to the response variable)\n",
    "\n",
    "#Function for Root mean squared error\n",
    "#https://stackoverflow.com/questions/17197492/root-mean-square-error-in-python\n",
    "def rmse(y_actual, y_predicted):\n",
    "    return np.sqrt(mean_squared_error(y_actual, y_predicted))\n",
    "\n",
    "#Function for Mean Absolute Percentage Error (MAPE) - Untested\n",
    "#Adapted from - https://stackoverflow.com/questions/42250958/how-to-optimize-mape-code-in-python\n",
    "def mape(y_actual, y_predicted): \n",
    "    mask = y_actual != 0\n",
    "    return (np.fabs(y_actual - y_predicted)/y_actual)[mask].mean() * 100\n",
    "\n",
    "#Create scorers for rmse and mape functions\n",
    "mae_scorer = make_scorer(score_func=mean_absolute_error, greater_is_better=False)\n",
    "rmse_scorer = make_scorer(score_func=rmse, greater_is_better=False)\n",
    "mape_scorer = make_scorer(score_func=mape, greater_is_better=False)\n",
    "\n",
    "#Make scorer array to pass into cross_validate() function for producing mutiple scores for each cv fold.\n",
    "errorScoring = {'MAE':  mae_scorer, \n",
    "                'RMSE': rmse_scorer,\n",
    "                'MAPE': mape_scorer\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code used to evaluate regression models used\n",
    "# code from Dr. Drew github: https://github.com/jakemdrew/EducationDataNC/blob/master/Other%20Projects/iPython%20Notebooks/Machine%20Learning/High%20School%20Minority%20Percentage%20February%202018.ipynb\n",
    "\n",
    "def EvaluateRegressionEstimator(regEstimator, X, y, cv):\n",
    "    \n",
    "    scores = cross_validate(regEstimator, X, y, scoring=errorScoring, cv=cv, return_train_score=True)\n",
    "\n",
    "    #cross val score sign-flips the outputs of MAE\n",
    "    # https://github.com/scikit-learn/scikit-learn/issues/2439\n",
    "    scores['test_MAE'] = scores['test_MAE'] * -1\n",
    "    scores['test_MAPE'] = scores['test_MAPE'] * -1\n",
    "    scores['test_RMSE'] = scores['test_RMSE'] * -1\n",
    "\n",
    "    #print mean MAE for all folds \n",
    "    maeAvg = scores['test_MAE'].mean()\n",
    "    print_str = \"The average MAE for all cv folds is: \\t\\t\\t {maeAvg:.5}\"\n",
    "    print(print_str.format(maeAvg=maeAvg))\n",
    "\n",
    "    #print mean test_MAPE for all folds\n",
    "    scores['test_MAPE'] = scores['test_MAPE']\n",
    "    mape_avg = scores['test_MAPE'].mean()\n",
    "    print_str = \"The average MAE percentage (MAPE) for all cv folds is: \\t {mape_avg:.5}\"\n",
    "    print(print_str.format(mape_avg=mape_avg))\n",
    "\n",
    "    #print mean MAE for all folds \n",
    "    RMSEavg = scores['test_RMSE'].mean()\n",
    "    print_str = \"The average RMSE for all cv folds is: \\t\\t\\t {RMSEavg:.5}\"\n",
    "    print(print_str.format(RMSEavg=RMSEavg))\n",
    "    print('*********************************************************')\n",
    "\n",
    "    print('Cross Validation Fold Mean Error Scores')\n",
    "    scoresResults = pd.DataFrame()\n",
    "    scoresResults['MAE'] = scores['test_MAE']\n",
    "    scoresResults['MAPE'] = scores['test_MAPE']\n",
    "    scoresResults['RMSE'] = scores['test_RMSE']\n",
    "    return scoresResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Clovis\\Documents\\7331DataMining\\EducationDataNC\\2017\\Machine Learning Datasets\n"
     ]
    }
   ],
   "source": [
    "# Brett's directory\n",
    "# Laptop\n",
    "#%cd \"C:\\sandbox\\SMU\\dataMining\\choNotebook\\EducationDataNC\\2017\\Machine Learning Datasets\"\n",
    "\n",
    "# Ryan's directory\n",
    "%cd \"C:\\Users\\Clovis\\Documents\\7331DataMining\\EducationDataNC\\2017\\Machine Learning Datasets\"\n",
    "\n",
    "# Cho's directory\n",
    "#%cd \"/Users/chostone/Documents/Data Mining/7331DataMining/EducationDataNC/2017/Machine Learning Datasets\"\n",
    "\n",
    "# NW directory\n",
    "#%cd \"C:\\Users\\Nicole Wittlin\\Documents\\Classes\\MSDS7331\\Project\\2017\\Machine Learning Datasets\"\n",
    "\n",
    "dfPublicHS = pd.read_csv(\"PublicHighSchools2017_ML.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#want to delete any remaining variables related to the ACT score (such as ACT benchmarks) to not bias our model\n",
    "dfDropped = dfPublicHS\n",
    "\n",
    "dfDropped['Score'] = dfDropped['ACT Score']\n",
    "dropCols = dfDropped.filter(regex = r'ACT')\n",
    "\n",
    "dfDropped.drop(dropCols, axis = 1, inplace = True)\n",
    "\n",
    "dfDropped['ACT_Score'] = dfDropped['Score']\n",
    "del dfDropped['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 470 entries, 0 to 469\n",
      "Data columns (total 87 columns):\n",
      "ACT Score                                   470 non-null float64\n",
      "ACT WorkKeys Score                          470 non-null float64\n",
      "ACTMath_ACTBenchmark_All                    470 non-null float64\n",
      "ACTScience_ACTBenchmark_All                 470 non-null float64\n",
      "ACTWorkKeys_SilverPlus_All                  470 non-null float64\n",
      "ACTWriting_ACTBenchmark_All                 470 non-null float64\n",
      "ACTCompositeScore_UNCMin_Female             470 non-null float64\n",
      "ACTEnglish_ACTBenchmark_Female              470 non-null float64\n",
      "ACTMath_ACTBenchmark_Female                 470 non-null float64\n",
      "ACTReading_ACTBenchmark_Female              470 non-null float64\n",
      "ACTScience_ACTBenchmark_Female              470 non-null float64\n",
      "ACTWorkKeys_SilverPlus_Female               470 non-null float64\n",
      "ACTCompositeScore_UNCMin_Male               470 non-null float64\n",
      "ACTMath_ACTBenchmark_Male                   470 non-null float64\n",
      "ACTScience_ACTBenchmark_Male                470 non-null float64\n",
      "ACTWorkKeys_SilverPlus_Male                 470 non-null float64\n",
      "ACTWriting_ACTBenchmark_Male                470 non-null float64\n",
      "ACTCompositeScore_UNCMin_AmericanIndian     470 non-null float64\n",
      "ACTMath_ACTBenchmark_AmericanIndian         470 non-null float64\n",
      "ACTSubtests_BenchmarksMet_AmericanIndian    470 non-null float64\n",
      "ACTWorkKeys_SilverPlus_AmericanIndian       470 non-null float64\n",
      "ACTWriting_ACTBenchmark_AmericanIndian      470 non-null float64\n",
      "ACTCompositeScore_UNCMin_Asian              470 non-null float64\n",
      "ACTSubtests_BenchmarksMet_Asian             470 non-null float64\n",
      "ACTWorkKeys_SilverPlus_Asian                470 non-null float64\n",
      "ACTWriting_ACTBenchmark_Asian               470 non-null float64\n",
      "ACTCompositeScore_UNCMin_Black              470 non-null float64\n",
      "ACTEnglish_ACTBenchmark_Black               470 non-null float64\n",
      "ACTMath_ACTBenchmark_Black                  470 non-null float64\n",
      "ACTReading_ACTBenchmark_Black               470 non-null float64\n",
      "ACTScience_ACTBenchmark_Black               470 non-null float64\n",
      "ACTSubtests_BenchmarksMet_Black             470 non-null float64\n",
      "ACTWorkKeys_SilverPlus_Black                470 non-null float64\n",
      "ACTWriting_ACTBenchmark_Black               470 non-null float64\n",
      "ACTCompositeScore_UNCMin_Hispanic           470 non-null float64\n",
      "ACTEnglish_ACTBenchmark_Hispanic            470 non-null float64\n",
      "ACTMath_ACTBenchmark_Hispanic               470 non-null float64\n",
      "ACTReading_ACTBenchmark_Hispanic            470 non-null float64\n",
      "ACTScience_ACTBenchmark_Hispanic            470 non-null float64\n",
      "ACTSubtests_BenchmarksMet_Hispanic          470 non-null float64\n",
      "ACTWorkKeys_SilverPlus_Hispanic             470 non-null float64\n",
      "ACTWriting_ACTBenchmark_Hispanic            470 non-null float64\n",
      "ACTCompositeScore_UNCMin_TwoorMoreRaces     470 non-null float64\n",
      "ACTMath_ACTBenchmark_TwoorMoreRaces         470 non-null float64\n",
      "ACTReading_ACTBenchmark_TwoorMoreRaces      470 non-null float64\n",
      "ACTScience_ACTBenchmark_TwoorMoreRaces      470 non-null float64\n",
      "ACTSubtests_BenchmarksMet_TwoorMoreRaces    470 non-null float64\n",
      "ACTWorkKeys_SilverPlus_TwoorMoreRaces       470 non-null float64\n",
      "ACTWriting_ACTBenchmark_TwoorMoreRaces      470 non-null float64\n",
      "ACTCompositeScore_UNCMin_White              470 non-null float64\n",
      "ACTMath_ACTBenchmark_White                  470 non-null float64\n",
      "ACTScience_ACTBenchmark_White               470 non-null float64\n",
      "ACTSubtests_BenchmarksMet_White             470 non-null float64\n",
      "ACTWorkKeys_SilverPlus_White                470 non-null float64\n",
      "ACTWriting_ACTBenchmark_White               470 non-null float64\n",
      "ACTCompositeScore_UNCMin_EDS                470 non-null float64\n",
      "ACTEnglish_ACTBenchmark_EDS                 470 non-null float64\n",
      "ACTMath_ACTBenchmark_EDS                    470 non-null float64\n",
      "ACTReading_ACTBenchmark_EDS                 470 non-null float64\n",
      "ACTScience_ACTBenchmark_EDS                 470 non-null float64\n",
      "ACTSubtests_BenchmarksMet_EDS               470 non-null float64\n",
      "ACTWorkKeys_SilverPlus_EDS                  470 non-null float64\n",
      "ACTWriting_ACTBenchmark_EDS                 470 non-null float64\n",
      "ACTCompositeScore_UNCMin_LEP                470 non-null float64\n",
      "ACTEnglish_ACTBenchmark_LEP                 470 non-null float64\n",
      "ACTMath_ACTBenchmark_LEP                    470 non-null float64\n",
      "ACTReading_ACTBenchmark_LEP                 470 non-null float64\n",
      "ACTScience_ACTBenchmark_LEP                 470 non-null float64\n",
      "ACTSubtests_BenchmarksMet_LEP               470 non-null float64\n",
      "ACTWorkKeys_SilverPlus_LEP                  470 non-null float64\n",
      "ACTWriting_ACTBenchmark_LEP                 470 non-null float64\n",
      "ACTCompositeScore_UNCMin_SWD                470 non-null float64\n",
      "ACTEnglish_ACTBenchmark_SWD                 470 non-null float64\n",
      "ACTMath_ACTBenchmark_SWD                    470 non-null float64\n",
      "ACTReading_ACTBenchmark_SWD                 470 non-null float64\n",
      "ACTScience_ACTBenchmark_SWD                 470 non-null float64\n",
      "ACTSubtests_BenchmarksMet_SWD               470 non-null float64\n",
      "ACTWorkKeys_SilverPlus_SWD                  470 non-null float64\n",
      "ACTWriting_ACTBenchmark_SWD                 470 non-null float64\n",
      "ACTCompositeScore_UNCMin_AIG                470 non-null float64\n",
      "ACTMath_ACTBenchmark_AIG                    470 non-null float64\n",
      "ACTScience_ACTBenchmark_AIG                 470 non-null float64\n",
      "ACTSubtests_BenchmarksMet_AIG               470 non-null float64\n",
      "ACTWorkKeys_SilverPlus_AIG                  470 non-null float64\n",
      "ACTWriting_ACTBenchmark_AIG                 470 non-null float64\n",
      "ACT_pTarget_PctMet                          470 non-null float64\n",
      "ACTWorkKeys_pTarget_PctMet                  470 non-null float64\n",
      "dtypes: float64(87)\n",
      "memory usage: 319.5 KB\n"
     ]
    }
   ],
   "source": [
    "#list of all the columns that were deleted (note that ACT Score was put back into dataframe that is being used)\n",
    "dropCols.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 470 entries, 0 to 469\n",
      "Empty DataFrame"
     ]
    }
   ],
   "source": [
    "dropColsPrin = dfDropped.filter(regex = r'prin')\n",
    "\n",
    "dfDropped.drop(dropColsPrin, axis = 1, inplace = True)\n",
    "\n",
    "dropColsPrin.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_num</th>\n",
       "      <th>lea_avg_student_num</th>\n",
       "      <th>st_avg_student_num</th>\n",
       "      <th>09_Size</th>\n",
       "      <th>10_Size</th>\n",
       "      <th>11_Size</th>\n",
       "      <th>12_Size</th>\n",
       "      <th>Biology_Size</th>\n",
       "      <th>English II_Size</th>\n",
       "      <th>Math I_Size</th>\n",
       "      <th>...</th>\n",
       "      <th>SRC_Grades_Devices_Sent_Home_6:7:8:9:10:11:12</th>\n",
       "      <th>SRC_Grades_Devices_Sent_Home_6:7:8:9:10:11:12:13</th>\n",
       "      <th>SRC_Grades_Devices_Sent_Home_8:9:10:11:12:13</th>\n",
       "      <th>SRC_Grades_Devices_Sent_Home_9:10</th>\n",
       "      <th>SRC_Grades_Devices_Sent_Home_9:10:11</th>\n",
       "      <th>SRC_Grades_Devices_Sent_Home_9:10:11:12</th>\n",
       "      <th>SRC_Grades_Devices_Sent_Home_9:10:11:12:13</th>\n",
       "      <th>SRC_Grades_Devices_Sent_Home_9:10:12</th>\n",
       "      <th>unit_code</th>\n",
       "      <th>ACT_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>834.336170</td>\n",
       "      <td>823.078723</td>\n",
       "      <td>833.417021</td>\n",
       "      <td>18.251064</td>\n",
       "      <td>17.534043</td>\n",
       "      <td>17.117021</td>\n",
       "      <td>15.623404</td>\n",
       "      <td>18.159574</td>\n",
       "      <td>19.110638</td>\n",
       "      <td>17.991489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>0.002128</td>\n",
       "      <td>0.002128</td>\n",
       "      <td>0.002128</td>\n",
       "      <td>0.017021</td>\n",
       "      <td>0.263830</td>\n",
       "      <td>0.078723</td>\n",
       "      <td>0.002128</td>\n",
       "      <td>513869.680851</td>\n",
       "      <td>59.182979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>593.357073</td>\n",
       "      <td>360.428092</td>\n",
       "      <td>97.416634</td>\n",
       "      <td>8.414169</td>\n",
       "      <td>9.269129</td>\n",
       "      <td>8.807896</td>\n",
       "      <td>9.262385</td>\n",
       "      <td>5.636281</td>\n",
       "      <td>5.644826</td>\n",
       "      <td>5.559518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065163</td>\n",
       "      <td>0.046127</td>\n",
       "      <td>0.046127</td>\n",
       "      <td>0.046127</td>\n",
       "      <td>0.129488</td>\n",
       "      <td>0.441178</td>\n",
       "      <td>0.269594</td>\n",
       "      <td>0.046127</td>\n",
       "      <td>282797.834670</td>\n",
       "      <td>22.639111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10303.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>312.750000</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>280307.000000</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>758.500000</td>\n",
       "      <td>810.000000</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>505332.000000</td>\n",
       "      <td>59.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1208.500000</td>\n",
       "      <td>974.000000</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>21.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>770348.750000</td>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2966.000000</td>\n",
       "      <td>1852.000000</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>995330.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 317 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       student_num  lea_avg_student_num  st_avg_student_num     09_Size  \\\n",
       "count   470.000000           470.000000          470.000000  470.000000   \n",
       "mean    834.336170           823.078723          833.417021   18.251064   \n",
       "std     593.357073           360.428092           97.416634    8.414169   \n",
       "min       8.000000           105.000000          278.000000    0.000000   \n",
       "25%     312.750000           577.000000          853.000000   16.000000   \n",
       "50%     758.500000           810.000000          853.000000   20.000000   \n",
       "75%    1208.500000           974.000000          853.000000   23.000000   \n",
       "max    2966.000000          1852.000000          853.000000   94.000000   \n",
       "\n",
       "          10_Size     11_Size     12_Size  Biology_Size  English II_Size  \\\n",
       "count  470.000000  470.000000  470.000000    470.000000       470.000000   \n",
       "mean    17.534043   17.117021   15.623404     18.159574        19.110638   \n",
       "std      9.269129    8.807896    9.262385      5.636281         5.644826   \n",
       "min      0.000000    0.000000    0.000000      0.000000         0.000000   \n",
       "25%     15.000000   14.000000   11.000000     15.000000        17.000000   \n",
       "50%     20.000000   20.000000   18.000000     19.000000        20.000000   \n",
       "75%     23.000000   24.000000   22.000000     22.000000        23.000000   \n",
       "max     92.000000   30.000000   36.000000     30.000000        30.000000   \n",
       "\n",
       "       Math I_Size     ...      SRC_Grades_Devices_Sent_Home_6:7:8:9:10:11:12  \\\n",
       "count   470.000000     ...                                         470.000000   \n",
       "mean     17.991489     ...                                           0.004255   \n",
       "std       5.559518     ...                                           0.065163   \n",
       "min       0.000000     ...                                           0.000000   \n",
       "25%      16.000000     ...                                           0.000000   \n",
       "50%      18.000000     ...                                           0.000000   \n",
       "75%      21.750000     ...                                           0.000000   \n",
       "max      32.000000     ...                                           1.000000   \n",
       "\n",
       "       SRC_Grades_Devices_Sent_Home_6:7:8:9:10:11:12:13  \\\n",
       "count                                        470.000000   \n",
       "mean                                           0.002128   \n",
       "std                                            0.046127   \n",
       "min                                            0.000000   \n",
       "25%                                            0.000000   \n",
       "50%                                            0.000000   \n",
       "75%                                            0.000000   \n",
       "max                                            1.000000   \n",
       "\n",
       "       SRC_Grades_Devices_Sent_Home_8:9:10:11:12:13  \\\n",
       "count                                    470.000000   \n",
       "mean                                       0.002128   \n",
       "std                                        0.046127   \n",
       "min                                        0.000000   \n",
       "25%                                        0.000000   \n",
       "50%                                        0.000000   \n",
       "75%                                        0.000000   \n",
       "max                                        1.000000   \n",
       "\n",
       "       SRC_Grades_Devices_Sent_Home_9:10  \\\n",
       "count                         470.000000   \n",
       "mean                            0.002128   \n",
       "std                             0.046127   \n",
       "min                             0.000000   \n",
       "25%                             0.000000   \n",
       "50%                             0.000000   \n",
       "75%                             0.000000   \n",
       "max                             1.000000   \n",
       "\n",
       "       SRC_Grades_Devices_Sent_Home_9:10:11  \\\n",
       "count                            470.000000   \n",
       "mean                               0.017021   \n",
       "std                                0.129488   \n",
       "min                                0.000000   \n",
       "25%                                0.000000   \n",
       "50%                                0.000000   \n",
       "75%                                0.000000   \n",
       "max                                1.000000   \n",
       "\n",
       "       SRC_Grades_Devices_Sent_Home_9:10:11:12  \\\n",
       "count                               470.000000   \n",
       "mean                                  0.263830   \n",
       "std                                   0.441178   \n",
       "min                                   0.000000   \n",
       "25%                                   0.000000   \n",
       "50%                                   0.000000   \n",
       "75%                                   1.000000   \n",
       "max                                   1.000000   \n",
       "\n",
       "       SRC_Grades_Devices_Sent_Home_9:10:11:12:13  \\\n",
       "count                                  470.000000   \n",
       "mean                                     0.078723   \n",
       "std                                      0.269594   \n",
       "min                                      0.000000   \n",
       "25%                                      0.000000   \n",
       "50%                                      0.000000   \n",
       "75%                                      0.000000   \n",
       "max                                      1.000000   \n",
       "\n",
       "       SRC_Grades_Devices_Sent_Home_9:10:12      unit_code   ACT_Score  \n",
       "count                            470.000000     470.000000  470.000000  \n",
       "mean                               0.002128  513869.680851   59.182979  \n",
       "std                                0.046127  282797.834670   22.639111  \n",
       "min                                0.000000   10303.000000    0.000000  \n",
       "25%                                0.000000  280307.000000   46.000000  \n",
       "50%                                0.000000  505332.000000   59.000000  \n",
       "75%                                0.000000  770348.750000   73.000000  \n",
       "max                                1.000000  995330.000000  100.000000  \n",
       "\n",
       "[8 rows x 317 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfDropped.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a> \n",
    "## Data Understanding (20 points total)\n",
    "<a id=\"data1\"></a>\n",
    "### Data Understanding 1 (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue\">Describe the meaning and type of data (scale, values, etc.) for each attribute in the data file. Verify data quality: Are there missing values? Duplicate data? Outliers? Are those mistakes? How do you deal with these problems?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a> \n",
    "<a id=\"data2\"></a>\n",
    "### Data Understanding 2 (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue\">Visualize the any important attributes appropriately. Important: Provide an interpretation for any charts or graphs.\n",
    "\n",
    "<span style=\"color: blue\">Note: \"Visualize the any\" is verbatim from syllabus</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a> \n",
    "## Modeling and Evaluation (50 points total)\n",
    "\n",
    "<span style=\"color: blue\">Different tasks will require different evaluation methods. Be as thorough as possible when analyzing the data you have chosen and use visualizations of the results to explain the performance and expected outcomes whenever possible. Guide the reader through your analysis with plenty of discussion of the results. Each option is broken down by: \n",
    "\n",
    "<ul style = \"color: blue\">\n",
    "<li>Train and Adjust Parameters</li>\n",
    "<li>Evaluate and Compare</li>\n",
    "<li>Visualize Results</li>\n",
    "<li>Summarize the Ramifications</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul style=\"color: blue\">\n",
    "<li><strong>Option A: Cluster Analysis</strong></li>\n",
    "    <ul style=\"color: blue\">\n",
    "    <li><strong>Train</strong>: Perform cluster analysis using several clustering methods (adjust parameters).</li>\n",
    "    <li><strong>Eval</strong>: Use internal and/or external validation measures to describe and compare the clusterings and the clusters — how did you determine a suitable number of clusters for each method?</li>\n",
    "    <li><strong>Visualize</strong>: Use tables/visualization to discuss the found results. Explain each visualization in detail.</li>\n",
    "    <li><strong>Summarize</strong>: Describe your results. What findings are the most interesting and why?</li>\n",
    "    </ul></ul>\n",
    "\n",
    "<ul style=\"color: blue\">\n",
    "<li><strong>Option B: Association Rule Mining</strong></li>\n",
    "    <ul style=\"color: blue\">\n",
    "    <li><strong>Train</strong>: Create frequent itemsets and association rules (adjust parameters).</li>\n",
    "    <li><strong>Eval</strong>: Use several measure for evaluating how interesting different rules are.</li>\n",
    "    <li><strong>Visualize</strong>: Use tables/visualization to discuss the found results.</li>\n",
    "<li><strong>Summarize</strong>: Describe your results. What findings are the most interesting and why?</li>\n",
    "    </ul></ul>\n",
    "\n",
    "<ul style = \"color: blue\">\n",
    "<li><strong>Option C: Collaborative Filtering</strong></li>\n",
    "    <ul style=\"color: blue\">\n",
    "    <li><strong>Train</strong>: Create user-item matrices or item-item matrices using collaborative filtering (adjust parameters).</li>\n",
    "    <li><strong>Eval</strong>: Determine performance of the recommendations using different performance measures (explain the ramifications of each measure).</li>\n",
    "    <li><strong>Visualize</strong>: Use tables/visualization to discuss the found results. Explain each visualization in detail.</li>\n",
    "    <li><strong>Summarize</strong>: Describe your results. What findings are the most interesting and why?</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a> \n",
    "<a id=\"Model1\"></a>\n",
    "### Train and Adjust Parameters (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a> \n",
    "<a id=\"Model2\"></a>\n",
    "### Evaluate and Compare (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a> \n",
    "<a id=\"Model3\"></a>\n",
    "### Visualize Results (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a> \n",
    "<a id=\"Model4\"></a>\n",
    "### Summarize the Ramifications (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a> \n",
    "<a id=\"Deployment\"></a>\n",
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue\">Be critical of your performance and tell the reader how *your* current model might be usable by other parties. Did you achieve your goals? If not, can you reign in the utility of your modeling?\n",
    "\n",
    "<ul style=\"color: blue\">\n",
    "<li>How useful is your model for interested parties (i.e., the companies of organizations that might want to use it)?</li>\n",
    "<li>How would *you* deploy your model for interested parties?</li>\n",
    "<li>What other data should be collected</li>\n",
    "<li>How often would the model need to be updated, etc. ?</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a> \n",
    "<a id=\"Exceptional\"></a>\n",
    "## Exceptional Work (10 points total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue\">You have free reign to provide additional analyses or combine analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

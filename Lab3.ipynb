{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: CRISP-DM Capstone\n",
    "## Association Rule Mining, Clustering, or Collaborative Filtering\n",
    "\n",
    "### Ryan Bass, Brett Benefield, Cho Kim, Nicole Wittlin\n",
    "\n",
    "<a id=\"top\"></a>\n",
    "## Contents\n",
    "* Business Understanding\n",
    "* Data Understanding\n",
    "    * <a href=\"#data1\">Data Understanding 1</a>\n",
    "    * <a href=\"#data2\">Data Understanding 2</a>\n",
    "* Modeling and Evaluation\n",
    "    * <a href=\"#Model1\">Train and Adjust Parameters</a>\n",
    "    * <a href=\"#Model2\">Evaluate and Compare</a>\n",
    "    * <a href=\"#Model3\">Visualize Results</a>\n",
    "    * <a href=\"#Model4\">Summarize the Ramifications</a>\n",
    "* <a href=\"#Deployment\">Deployment</a>\n",
    "* <a href=\"#Exceptional\">Exceptional Work</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yellowbrick as yb\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from sklearn import metrics as mt\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectFromModel, SelectPercentile, f_regression, mutual_info_regression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, accuracy_score, f1_score, roc_auc_score, mean_absolute_error, make_scorer, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler, Binarizer, scale\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC, SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression, SGDClassifier, RidgeClassifier, LinearRegression\n",
    "from sklearn.linear_model import Ridge, Lasso, LassoCV\n",
    "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, StratifiedShuffleSplit, StratifiedKFold, GridSearchCV, cross_validate, RandomizedSearchCV\n",
    "from yellowbrick.classifier import ClassificationReport, ConfusionMatrix, ClassPredictionError, ROCAUC\n",
    "from yellowbrick.features import Rank1D, Rank2D, RFECV\n",
    "from yellowbrick.features.importances import FeatureImportances\n",
    "from yellowbrick.model_selection import ValidationCurve, LearningCurve\n",
    "from yellowbrick.regressor import PredictionError, ResidualsPlot\n",
    "from yellowbrick.regressor.alphas import AlphaSelection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slack Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some setup is required before you can use this because token must be kept private\n",
    "# I also need to add your name and unique identifier to the dictionary userID below\n",
    "import os\n",
    "from slackclient import SlackClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "userID = {\"brett\": \"UAN6UQEVC\", \"ryan\": \"UALUD69AB\"}\n",
    "\n",
    "#slackToken = os.environ[\"SLACK_BOT_TOKEN\"]\n",
    "#sc = SlackClient(slackToken)\n",
    "\n",
    "def sendSlackMessage(msg, user):\n",
    "    result = sc.api_call(\n",
    "    \"chat.postMessage\",\n",
    "    channel=userID[user.lower()],\n",
    "    text=msg)\n",
    "    \n",
    "    if (not result['ok']):\n",
    "        print(\"Error: {}\".format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supporting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://medium.com/@aneesha/visualising-top-features-in-linear-svm-with-scikit-learn-and-matplotlib-3454ab18a14d\n",
    "def plot_coefficients(classifier, feature_names, top_features=20):\n",
    "    coef = classifier.coef_.ravel()\n",
    "    top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
    "    top_negative_coefficients = np.argsort(coef)[:top_features]\n",
    "    top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
    "    # create plot\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    colors = [\"red\" if c < 0 else \"blue\" for c in coef[top_coefficients]]\n",
    "    plt.bar(np.arange(2 * top_features), coef[top_coefficients], color=colors)\n",
    "    feature_names = np.array(feature_names)\n",
    "    plt.xticks(np.arange(1, 1 + 2 * top_features), feature_names[top_coefficients], rotation=60, ha=\"right\")\n",
    "    plt.show()\n",
    "    \n",
    "def getTopCoefficients(classifier, feature_names, top_features=20):\n",
    "    coef = classifier.coef_.ravel()\n",
    "    top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
    "    top_negative_coefficients = np.argsort(coef)[:top_features]\n",
    "    top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
    "    feature_names = np.array(feature_names)\n",
    "    return feature_names[top_coefficients]\n",
    "\n",
    "# Source: https://stackoverflow.com/questions/39812885/retain-feature-names-after-scikit-feature-selection\n",
    "def percentile_threshold_selector(data, percent=10):\n",
    "    selector = SelectPercentile(f_classif, percentile = percent)\n",
    "    selector.fit(data)\n",
    "    return data[data.columns[selector.get_support(indices=True)]]\n",
    "\n",
    "def scale_data(data):\n",
    "    temp = scaler.fit(data)\n",
    "    data = pd.DataFrame(temp, columns = data.columns)\n",
    "    return data\n",
    "\n",
    "# https://stackoverflow.com/questions/17778394/list-highest-correlation-pairs-from-a-large-correlation-matrix-in-pandas\n",
    "def get_redundant_pairs(df):\n",
    "    '''Get diagonal and lower triangular pairs of correlation matrix'''\n",
    "    pairs_to_drop = set()\n",
    "    cols = df.columns\n",
    "    for i in range(0, df.shape[1]):\n",
    "        for j in range(0, i+1):\n",
    "            pairs_to_drop.add((cols[i], cols[j]))\n",
    "    return pairs_to_drop\n",
    "\n",
    "def get_top_abs_correlations(df, n=5):\n",
    "    au_corr = df.corr().abs().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr[0:n]\n",
    "\n",
    "# rmse, mape functions take from :https://github.com/jakemdrew/EducationDataNC/blob/master/Other%20Projects/iPython%20Notebooks/Machine%20Learning/High%20School%20Minority%20Percentage%20February%202018.ipynb\n",
    "#Use mean absolute error (MAE) to score the regression models created \n",
    "#(the scale of MAE is identical to the response variable)\n",
    "\n",
    "#Function for Root mean squared error\n",
    "#https://stackoverflow.com/questions/17197492/root-mean-square-error-in-python\n",
    "def rmse(y_actual, y_predicted):\n",
    "    return np.sqrt(mean_squared_error(y_actual, y_predicted))\n",
    "\n",
    "#Function for Mean Absolute Percentage Error (MAPE) - Untested\n",
    "#Adapted from - https://stackoverflow.com/questions/42250958/how-to-optimize-mape-code-in-python\n",
    "def mape(y_actual, y_predicted): \n",
    "    mask = y_actual != 0\n",
    "    return (np.fabs(y_actual - y_predicted)/y_actual)[mask].mean() * 100\n",
    "\n",
    "#Create scorers for rmse and mape functions\n",
    "mae_scorer = make_scorer(score_func=mean_absolute_error, greater_is_better=False)\n",
    "rmse_scorer = make_scorer(score_func=rmse, greater_is_better=False)\n",
    "mape_scorer = make_scorer(score_func=mape, greater_is_better=False)\n",
    "\n",
    "#Make scorer array to pass into cross_validate() function for producing mutiple scores for each cv fold.\n",
    "errorScoring = {'MAE':  mae_scorer, \n",
    "                'RMSE': rmse_scorer,\n",
    "                'MAPE': mape_scorer\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code used to evaluate regression models used\n",
    "# code from Dr. Drew github: https://github.com/jakemdrew/EducationDataNC/blob/master/Other%20Projects/iPython%20Notebooks/Machine%20Learning/High%20School%20Minority%20Percentage%20February%202018.ipynb\n",
    "\n",
    "def EvaluateRegressionEstimator(regEstimator, X, y, cv):\n",
    "    \n",
    "    scores = cross_validate(regEstimator, X, y, scoring=errorScoring, cv=cv, return_train_score=True)\n",
    "\n",
    "    #cross val score sign-flips the outputs of MAE\n",
    "    # https://github.com/scikit-learn/scikit-learn/issues/2439\n",
    "    scores['test_MAE'] = scores['test_MAE'] * -1\n",
    "    scores['test_MAPE'] = scores['test_MAPE'] * -1\n",
    "    scores['test_RMSE'] = scores['test_RMSE'] * -1\n",
    "\n",
    "    #print mean MAE for all folds \n",
    "    maeAvg = scores['test_MAE'].mean()\n",
    "    print_str = \"The average MAE for all cv folds is: \\t\\t\\t {maeAvg:.5}\"\n",
    "    print(print_str.format(maeAvg=maeAvg))\n",
    "\n",
    "    #print mean test_MAPE for all folds\n",
    "    scores['test_MAPE'] = scores['test_MAPE']\n",
    "    mape_avg = scores['test_MAPE'].mean()\n",
    "    print_str = \"The average MAE percentage (MAPE) for all cv folds is: \\t {mape_avg:.5}\"\n",
    "    print(print_str.format(mape_avg=mape_avg))\n",
    "\n",
    "    #print mean MAE for all folds \n",
    "    RMSEavg = scores['test_RMSE'].mean()\n",
    "    print_str = \"The average RMSE for all cv folds is: \\t\\t\\t {RMSEavg:.5}\"\n",
    "    print(print_str.format(RMSEavg=RMSEavg))\n",
    "    print('*********************************************************')\n",
    "\n",
    "    print('Cross Validation Fold Mean Error Scores')\n",
    "    scoresResults = pd.DataFrame()\n",
    "    scoresResults['MAE'] = scores['test_MAE']\n",
    "    scoresResults['MAPE'] = scores['test_MAPE']\n",
    "    scoresResults['RMSE'] = scores['test_RMSE']\n",
    "    return scoresResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'C:\\\\sandbox\\\\SMU\\\\dataMining\\\\choNotebook\\\\EducationDataNC\\\\2017\\\\Machine Learning Datasets'\n",
      "/Users/chostone/Documents/Data Mining/7331DataMining\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-02591a72e867>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# NW directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#%cd \"C:\\Users\\Nicole Wittlin\\Documents\\Classes\\MSDS7331\\Project\\2017\\Machine Learning Datasets\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdfPublicHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PublicHighSchools2017_ML.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Brett's directory\n",
    "# Laptop\n",
    "%cd \"C:\\sandbox\\SMU\\dataMining\\choNotebook\\EducationDataNC\\2017\\Machine Learning Datasets\"\n",
    "\n",
    "# Ryan's directory\n",
    "#%cd \"C:\\Users\\Clovis\\Documents\\7331DataMining\\EducationDataNC\\2017\\Machine Learning Datasets\"\n",
    "\n",
    "# Cho's directory\n",
    "#%cd \"/Users/chostone/Documents/Data Mining/7331DataMining/EducationDataNC/2017/Machine Learning Datasets\"\n",
    "\n",
    "# NW directory\n",
    "#%cd \"C:\\Users\\Nicole Wittlin\\Documents\\Classes\\MSDS7331\\Project\\2017\\Machine Learning Datasets\"\n",
    "dfPublicHS = pd.read_csv(\"PublicHighSchools2017_ML.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a> \n",
    "## Data Understanding (20 points total)\n",
    "<a id=\"data1\"></a>\n",
    "### Data Understanding 1 (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue\">Describe the meaning and type of data (scale, values, etc.) for each attribute in the data file. Verify data quality: Are there missing values? Duplicate data? Outliers? Are those mistakes? How do you deal with these problems?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a> \n",
    "<a id=\"data2\"></a>\n",
    "### Data Understanding 2 (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue\">Visualize the any important attributes appropriately. Important: Provide an interpretation for any charts or graphs.\n",
    "\n",
    "<span style=\"color: blue\">Note: \"Visualize the any\" is verbatim from syllabus</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a> \n",
    "## Modeling and Evaluation (50 points total)\n",
    "\n",
    "<span style=\"color: blue\">Different tasks will require different evaluation methods. Be as thorough as possible when analyzing the data you have chosen and use visualizations of the results to explain the performance and expected outcomes whenever possible. Guide the reader through your analysis with plenty of discussion of the results. Each option is broken down by: \n",
    "\n",
    "<ul style = \"color: blue\">\n",
    "<li>Train and Adjust Parameters</li>\n",
    "<li>Evaluate and Compare</li>\n",
    "<li>Visualize Results</li>\n",
    "<li>Summarize the Ramifications</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul style=\"color: blue\">\n",
    "<li><strong>Option A: Cluster Analysis</strong></li>\n",
    "    <ul style=\"color: blue\">\n",
    "    <li><strong>Train</strong>: Perform cluster analysis using several clustering methods (adjust parameters).</li>\n",
    "    <li><strong>Eval</strong>: Use internal and/or external validation measures to describe and compare the clusterings and the clusters — how did you determine a suitable number of clusters for each method?</li>\n",
    "    <li><strong>Visualize</strong>: Use tables/visualization to discuss the found results. Explain each visualization in detail.</li>\n",
    "    <li><strong>Summarize</strong>: Describe your results. What findings are the most interesting and why?</li>\n",
    "    </ul></ul>\n",
    "\n",
    "<ul style=\"color: blue\">\n",
    "<li><strong>Option B: Association Rule Mining</strong></li>\n",
    "    <ul style=\"color: blue\">\n",
    "    <li><strong>Train</strong>: Create frequent itemsets and association rules (adjust parameters).</li>\n",
    "    <li><strong>Eval</strong>: Use several measure for evaluating how interesting different rules are.</li>\n",
    "    <li><strong>Visualize</strong>: Use tables/visualization to discuss the found results.</li>\n",
    "<li><strong>Summarize</strong>: Describe your results. What findings are the most interesting and why?</li>\n",
    "    </ul></ul>\n",
    "\n",
    "<ul style = \"color: blue\">\n",
    "<li><strong>Option C: Collaborative Filtering</strong></li>\n",
    "    <ul style=\"color: blue\">\n",
    "    <li><strong>Train</strong>: Create user-item matrices or item-item matrices using collaborative filtering (adjust parameters).</li>\n",
    "    <li><strong>Eval</strong>: Determine performance of the recommendations using different performance measures (explain the ramifications of each measure).</li>\n",
    "    <li><strong>Visualize</strong>: Use tables/visualization to discuss the found results. Explain each visualization in detail.</li>\n",
    "    <li><strong>Summarize</strong>: Describe your results. What findings are the most interesting and why?</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a> \n",
    "<a id=\"Model1\"></a>\n",
    "### Train and Adjust Parameters (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a> \n",
    "<a id=\"Model2\"></a>\n",
    "### Evaluate and Compare (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a> \n",
    "<a id=\"Model3\"></a>\n",
    "### Visualize Results (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a> \n",
    "<a id=\"Model4\"></a>\n",
    "### Summarize the Ramifications (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a> \n",
    "<a id=\"Deployment\"></a>\n",
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue\">Be critical of your performance and tell the reader how *your* current model might be usable by other parties. Did you achieve your goals? If not, can you reign in the utility of your modeling?\n",
    "\n",
    "<ul style=\"color: blue\">\n",
    "<li>How useful is your model for interested parties (i.e., the companies of organizations that might want to use it)?</li>\n",
    "<li>How would *you* deploy your model for interested parties?</li>\n",
    "<li>What other data should be collected</li>\n",
    "<li>How often would the model need to be updated, etc. ?</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a> \n",
    "<a id=\"Exceptional\"></a>\n",
    "## Exceptional Work (10 points total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue\">You have free reign to provide additional analyses or combine analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
